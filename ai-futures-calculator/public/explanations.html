<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Time horizon and the Automated Coder milestone</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Stage 1 of our model primarily predicts the trajectory of AIs’ coding skills. We focus on coding automation due to coding being a strength of current AIs relative to other AI R&amp;D tasks (and we focus on AI R&amp;D tasks so that we can use them to predict how AI R&amp;D automation will affect AI progress).</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">We extrapolate capabilities on the <a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/" title="" class="ltx_ref ltx_href">METR-HRS coding time horizon benchmark</a> in order to predict coding automation. We choose METR-HRS due to the relative feasibility of extrapolating it to very advanced capabilities, and the years-long time period for which we have past data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">The coding time horizon, <math id="S1.p3.m1" class="ltx_Math" alttext="H(t)" display="inline"><mrow><mi>H</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>, is the length of the coding tasks the frontier model can successfully complete 80% of the time, as measured by how long it takes humans to complete them. For example, if an AI has a 2 hour 80% time horizon, that means it can complete with an 80% success rate tasks that take human baseliners 2 hours (and for tasks that take baseliners more time, it has a lower success rate). METR has found that time horizon has been growing exponentially over the last 5 years, with a doubling time of roughly 7 months.</p>
</div>
<figure id="S1.fig1" class="ltx_figure"><img src="latex/METR_graph.png" id="S1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="256" alt="[Uncaptioned image]">
</figure>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">We want to predict when the <span class="ltx_text ltx_font_italic">Automated Coder (AC)</span> milestone is reached. An AC is a collective of AIs that, if dropped into the present day, would be as productive at coding as all present human coders with no AI assistance (using 5% of the compute of a present-day frontier AI project). A simple method for predicting the arrival date of an Automated Coder would be:</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Simple Method for forecasting Automated Coder.</span> <span class="ltx_text ltx_font_italic">Estimate what time horizon threshold (on an extended version of METR’s benchmark) would correspond to an Automated Coder, then use a straightforward exponential-in-time extrapolation of METR’s past data points to predict when this time horizon will be achieved.</span></p>
</div>
<details><summary id="why-an-80-success-rate-requirement">Why an 80% success rate requirement?</summary><div id="S1.p6" class="ltx_para">
<p class="ltx_p"> 80% is the highest success rate time horizon that METR considers high-quality. How is it possible that an 80% time horizon could correspond to dominating the average coder across all categories of tasks? (a) There is some randomness in whether an AI succeeds at an individual task, so even an AI that dominates average humans across all categories will not have 100% reliability at human-level or above efficiency on individual tasks. (b) We adjust the required 80% time horizon upward to account for increased reliability requirements. </p>
</div></details>
<details><summary id="efficiency-requirements-for-time-horizons">Efficiency requirements for time horizons.</summary><div id="S1.p7" class="ltx_para">
<p class="ltx_p"> We impose a constraint that the AI must accomplish tasks as efficiently as human researchers for a task completion to count as a success. See <a href="#S3.SS1" title="3.1 Coding automation fraction ‣ 3 Coding automation" class="ltx_ref">Coding Automation Fraction</a> for details about what we mean by “efficient automation”. The METR paper does not set an efficiency threshold, but we consider it necessary to set an efficiency threshold, given that AIs already sometimes accomplish tasks less efficiently than humans, and we expect this to become more important over time as AIs are better at translating more resources into better performance. </p>
</div></details>
<details><summary id="defining-our-theoretical-benchmark-metr-hrs-extended">Defining our theoretical benchmark METR-HRS-Extended.</summary><div id="S1.p8" class="ltx_para">
<p class="ltx_p"> Since METR-HRS only contains tasks that take human baseliners <math id="S1.p8.m1" class="ltx_Math" alttext="\leq" display="inline"><mo>≤</mo></math> 30 hours to complete and we want to forecast up to much higher levels, we define a procedure that could in principle be used to extend the task suite even though it would not be practical to actually do so. It’s important to define which human baseliners are used during the extension: the more competent they are, the larger an impact we should expect at any given time horizon. We assume that METR finds human baseliners who take the same amount of time to complete tasks as a typical AGI company programmer who does similar tasks. We think that this might be loosely consistent with their past baselining, and this also represents a simple assumption that translates relatively well to real-world impacts. </p>
</div></details>
<div id="S1.p9" class="ltx_para">
<p class="ltx_p">However, the Simple Method misses out on some important factors that we want to take into account, namely:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">The “time horizon vs calendar time” trend may be disrupted by changes in the growth of inputs to AI progress and the impact of AI automation.</span> For example, the growth of training compute growth may slow due to limits on investment and the speed of building new fabs. Meanwhile, the human labor growth may slow over time (“there are only so many people you can usefully hire”), but the AIs getting better at coding and research will increase the aggregate labor working on AI R&amp;D.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Time horizon may grow superexponentially or subexponentially in calendar time, even if input trends keep holding.</span> Although METR has observed roughly exponential time horizon growth, with successive time horizon doublings taking roughly the same amount of time, the trend could become superexponential or subexponential (in fact the trend looks slightly superexponential at the moment, but we don’t consider this as substantial evidence either way). Our best guess is that time horizon would grow superexponentially even absent AI R&amp;D automation, mainly because of the “long-horizon agency argument”: as an AI learns to complete increasingly long tasks, it will eventually develop better long-horizon agency skills (long-term planning, decomposing long tasks, noticing and correcting mistakes, etc.) than the human baseliners. On the other hand, one possible reason to expect subexponential growth, at least in the near-term, is data bottlenecks: it may be expensive to collect high-quality data for long-horizon tasks.</p>
</div>
</li>
</ol>
</div>
<div id="S1.p10" class="ltx_para">
<p class="ltx_p">The next subsections explain the additions we make to the Simple Method (which already includes a present doubling time<sup><a href="#fn1" id="fnref1">1</a></sup> parameter <math id="S1.p10.m1" class="ltx_Math" alttext="\tau" display="inline"><mi>τ</mi></math> and an Automated Coder time horizon requirement <math id="S1.p10.m2" class="ltx_Math" alttext="H_{\text{AC}}" display="inline"><msub><mi>H</mi><mtext>AC</mtext></msub></math>) to address these shortcomings. Here’s a brief summary:</p>
<ol id="S1.I2" class="ltx_enumerate">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p class="ltx_p">We track time horizon as a function of effective compute (which is a combination of training compute and software progress) rather than calendar time. In particular, to find the AC arrival time, the logic of our model is to first determine the effective compute <math id="S1.I2.i1.p1.m1" class="ltx_Math" alttext="E_{\text{AC}}" display="inline"><msub><mi>E</mi><mtext>AC</mtext></msub></math> corresponding to AC, then later find the AC arrival time by separately modeling the growth of effective compute.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p class="ltx_p">We add a doubling difficulty growth factor <math id="S1.I2.i2.p1.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> which determines whether (and the extent to which) time horizon grows superexponentially or subexponentially in <math id="S1.I2.i2.p1.m2" class="ltx_Math" alttext="\log(\text{effective compute})" display="inline"><mrow><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mtext>effective compute</mtext><mo stretchy="false">)</mo></mrow></mrow></math>. Each time horizon doubling requires an increase in log(effective compute) that’s <math id="S1.I2.i2.p1.m3" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> times larger than the previous doubling. (Note that we’ve converted the question of time horizon growing (super/sub)exponentially with calendar time to the question of time horizon growing (super/sub)exponentially with log(effective compute).)</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p class="ltx_p">We add an optional effective compute “gap” that is required to reach AC despite the required time horizon having been reached. This represents the gap between succeeding on very long METR-style benchmark coding tasks and automating coding in the real world.</p>
</div>
</li>
</ol>
</div>
<figure id="S1.fig2" class="ltx_figure"><img src="latex/time_horizon_growth.png" id="S1.g2" class="ltx_graphics ltx_img_landscape" width="598" height="372" alt="[Uncaptioned image]">
</figure>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Replacing calendar time with effective compute</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p class="ltx_p">As mentioned above, we want to move away from directly thinking of time horizon as a function of calendar time, since calendar time trends aren’t mechanistic enough for our purposes and they may change in the future (e.g. because training compute growth slows due to investment limits, AIs helping with R&amp;D introduces new dynamics, etc.). We chose to instead track time horizon (and other AI capabilities) as a function of <span class="ltx_text ltx_font_italic">effective compute</span>, which is directly sensitive to changing inputs to AI progress. By definition, effective compute <math id="S1.SS1.p1.m1" class="ltx_Math" alttext="E(t)" display="inline"><mrow><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is the amount of training compute we’d need to train models as performant as the frontier models at time <math id="S1.SS1.p1.m2" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> using the training process of the present-day. It’s a convenient metric that collapses software progress (i.e. more efficiently converting training compute into performance) onto the same axis as training compute. We’ll revisit the motivation and modeling of effective compute <a href="#S2" title="2 Modeling effective compute" class="ltx_ref">later</a>, after we finish explaining our modeling of time horizons and the Automated Coder milestone.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Time horizon progression</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p class="ltx_p">Both the METR-HRS time horizon and effective compute increased roughly exponentially over the last 5 years. Therefore one might expect an exponential relationship between the log of effective compute <math id="S1.SS2.p1.m1" class="ltx_Math" alttext="\log(E(t))" display="inline"><mrow><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mrow><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></math> and time horizon <math id="S1.SS2.p1.m2" class="ltx_Math" alttext="H(t)" display="inline"><mrow><mi>H</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>. We write <math id="S1.SS2.p1.m3" class="ltx_Math" alttext="\tau" display="inline"><mi>τ</mi></math> for the number of orders of magnitude (OOMs) of effective compute needed to double time horizon.<sup><a href="#fn2" id="fnref2">2</a></sup> Intuitively:</p>
<table id="S1.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S1.Ex1.m1" class="ltx_Math" alttext="\text{effective compute increases by $\tau$ OOMs}\quad\xrightarrow{\text{%
assumes exponential}}\quad\text{1 doubling of time horizon }" display="block"><mrow><mrow><mtext>effective compute increases by&#160;</mtext><mi>τ</mi><mtext>&#160;OOMs</mtext></mrow><mspace width="1em"></mspace><mover accent="true"><mo stretchy="false">→</mo><mtext>assumes exponential</mtext></mover><mspace width="1em"></mspace><mtext>1 doubling of time horizon&#160;</mtext></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S1.SS2.p2" class="ltx_para">
<p class="ltx_p">We primarily set <math id="S1.SS2.p2.m1" class="ltx_Math" alttext="\tau" display="inline"><mi>τ</mi></math> by fitting historical METR-HRS trends, balancing between the long-term observed trend and a potential recent uptick.</p>
</div>
<div id="S1.SS2.p3" class="ltx_para">
<p class="ltx_p">Now we address the second issue about the Simple Method we brought up, namely that the Simple Method assumes time horizon will keep growing exponentially as a function of <math id="S1.SS2.p3.m1" class="ltx_Math" alttext="\log(E(t))" display="inline"><mrow><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mrow><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></math>. We model the possibility that time horizon may grow superexponentially or subexponentially via a parameter <math id="S1.SS2.p3.m2" class="ltx_Math" alttext="d>0" display="inline"><mrow><mi>d</mi><mo>&gt;</mo><mn>0</mn></mrow></math>, which we call the doubling difficulty growth factor. The idea is that each time horizon doubling should require <math id="S1.SS2.p3.m3" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> times what the last time horizon doubling took (in OOMs of effective compute). So <math id="S1.SS2.p3.m4" class="ltx_Math" alttext="d=1" display="inline"><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow></math> corresponds to the exponential case, <math id="S1.SS2.p3.m5" class="ltx_Math" alttext="0<d<1" display="inline"><mrow><mn>0</mn><mo>&lt;</mo><mi>d</mi><mo>&lt;</mo><mn>1</mn></mrow></math> to the superexponential case, and <math id="S1.SS2.p3.m6" class="ltx_Math" alttext="d>1" display="inline"><mrow><mi>d</mi><mo>&gt;</mo><mn>1</mn></mrow></math> to the subexponential case.</p>
</div>
<figure id="S1.SS2.fig1" class="ltx_figure"><img src="latex/doubling_difficulty.png" id="S1.SS2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="171" alt="[Uncaptioned image]">
</figure>
<div id="S1.SS2.p4" class="ltx_para">
<p class="ltx_p">Our best guess is that time horizon should grow superexponentially with effective compute, so that <math id="S1.SS2.p4.m1" class="ltx_Math" alttext="d<1" display="inline"><mrow><mi>d</mi><mo>&lt;</mo><mn>1</mn></mrow></math>. This is primarily because we expect that once AIs surpass humans at long-horizon agency, they will have infinite or extremely large horizons, which imply superexponential growth. <span class="ltx_text" style="color:#0000FF;">ELI-TODO: Re-write this brief argument and the corresponding expandable. Mention that we don’t think all measures will go to inf.</span></p>
</div>
<details><summary id="when-ais-develop-better-long-horizon-agency-skills-than-humans-their-success-rates-may-not-decrease-even-as-tasks-get-longer">When AIs develop better long-horizon agency skills than humans, their success rates may not decrease even as tasks get longer.</summary><figure id="S1.SS2.fig2" class="ltx_figure"><img src="latex/infinite_horizons.png" id="S1.SS2.g2" class="ltx_graphics ltx_img_landscape" width="598" height="438" alt="[Uncaptioned image]">
</figure><div id="S1.SS2.p6" class="ltx_para">
<p class="ltx_p">Suppose we get AIs with better long-horizon agency skills than the METR-HRS-Extended human baseliners. If we plot the AIs’ success rate on tasks vs. the time it takes the human baseliners to complete those tasks (the “human-task-time”), what does that look like? There are three possibilities:</p>
<ol id="S1.I3" class="ltx_enumerate">
<li id="S1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I3.i1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">The success rate vs. human-task-time trend “flips” to AIs having higher success rates at higher human-task-times, leading to an infinite 80% time horizon</span>. This could happen because AIs are now differentially better at long-horizon tasks than humans, as opposed to short-horizon tasks (recall that time horizons are defined relative to humans, as opposed to some inherent property of the task). In this case, we think this should be interpreted as the METR-HRS-Extended time horizon being infinity in finite effective compute and that therefore we should expect superexponential time horizon growth leading up to this.</p>
</div>
</li>
<li id="S1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I3.i2.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">The success rate decreases with human-task-time, but it asymptotes above 80%, leading to an infinite 80% time horizon.</span> This could happen because, despite having better long-horion skills than the human baseliners, the AIs may have even better short-horizon skills.</p>
</div>
</li>
<li id="S1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I3.i3.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">The success rate drops below 80% but for extremely long human-task-times.</span> In this case, the 80% time horizon vs effective compute trend could be either exponential or superexponential, but there wouldn’t be a level of effective compute where the AIs have infinite 80% time horizon. The fact that the time horizons are extremely large suggests that it would still most likely be superexponential, based on some back-of-the-envelope calcluations.</p>
</div>
</li>
</ol>

</div></details>
<div id="S1.SS2.p7" class="ltx_para">
<p class="ltx_p">We write <math id="S1.SS2.p7.m1" class="ltx_Math" alttext="\overline{E}" display="inline"><mover accent="true"><mi>E</mi><mo>¯</mo></mover></math> for log(effective compute) in the formulas in the expandable boxes.</p>
</div>
<details><summary id="achievement-of-infinite-time-horizon-when-time-horizon-growth-is-superexponential">Achievement of infinite time horizon when time horizon growth is superexponential.</summary><div id="S1.SS2.p8" class="ltx_para">
<p class="ltx_p"> If <math id="S1.SS2.p8.m1" class="ltx_Math" alttext="0<d<1" display="inline"><mrow><mn>0</mn><mo>&lt;</mo><mi>d</mi><mo>&lt;</mo><mn>1</mn></mrow></math>, i.e. time horizon growth is superexponential, we get an infinite time horizon when</p>
<table id="S1.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S1.Ex2.m1" class="ltx_Math" alttext="\overline{E}=\overline{E}(\text{present-day})+\frac{\tau}{1-d}." display="block"><mrow><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>=</mo><mrow><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mfrac><mi>τ</mi><mrow><mn>1</mn><mo>−</mo><mi>d</mi></mrow></mfrac></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">As discussed previously, an infinite time horizon implies that AIs are more competent at long-horizon agency than human baseliners, <span class="ltx_text ltx_font_italic">not</span> that they have reached the limits of intelligence. </p>
</div></details>
<details><summary id="explicit-formula-for-time-horizon-including-superexponential-and-subexponential">Explicit formula for time horizon including superexponential and subexponential.</summary><div id="S1.SS2.p9" class="ltx_para">
<p class="ltx_p">
Starting from <math id="S1.SS2.p9.m1" class="ltx_Math" alttext="H(\text{present-day})" display="inline"><mrow><mi>H</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow></math>, the first doubling of time horizon requires <math id="S1.SS2.p9.m2" class="ltx_Math" alttext="\overline{E}" display="inline"><mover accent="true"><mi>E</mi><mo>¯</mo></mover></math> to increase by <math id="S1.SS2.p9.m3" class="ltx_Math" alttext="\tau" display="inline"><mi>τ</mi></math>, the second doubling by <math id="S1.SS2.p9.m4" class="ltx_Math" alttext="d\tau" display="inline"><mrow><mi>d</mi><mo>⁢</mo><mi>τ</mi></mrow></math>, the third doubling by <math id="S1.SS2.p9.m5" class="ltx_Math" alttext="d^{2}\tau" display="inline"><mrow><msup><mi>d</mi><mn>2</mn></msup><mo>⁢</mo><mi>τ</mi></mrow></math>, and so forth. Provided <math id="S1.SS2.p9.m6" class="ltx_Math" alttext="H(t)" display="inline"><mrow><mi>H</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is not infinite yet (which eventually happens for <math id="S1.SS2.p9.m7" class="ltx_Math" alttext="d<1" display="inline"><mrow><mi>d</mi><mo>&lt;</mo><mn>1</mn></mrow></math>), we can calculate an explicit formula for <math id="S1.SS2.p9.m8" class="ltx_Math" alttext="H(t)" display="inline"><mrow><mi>H</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>:</p>
<table id="S1.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S1.Ex3.m1" class="ltx_Math" alttext="H(t)=\begin{cases}H(\text{present-day})\cdot 2^{\frac{\overline{E}(t)-%
\overline{E}(\text{present-day})}{\tau}}&\text{if $d=1$};\\
H(\text{present-day})\cdot\left(1-(1-d)\frac{\overline{E}(t)-\overline{E}(%
\text{present-day})}{\tau}\right)^{\log_{d}2}&\text{if $d\neq 1$.}\end{cases}" display="block"><mrow><mrow><mi>H</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mi>H</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">⋅</mo><msup><mn>2</mn><mfrac><mrow><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>−</mo><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow></mrow><mi>τ</mi></mfrac></msup></mrow></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mtext>if&#160;</mtext><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow></mrow><mo>;</mo></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mi>H</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">⋅</mo><msup><mrow><mo>(</mo><mrow><mn>1</mn><mo>−</mo><mrow><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>−</mo><mi>d</mi></mrow><mo stretchy="false">)</mo></mrow><mo>⁢</mo><mstyle displaystyle="false"><mfrac><mrow><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>−</mo><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow></mrow><mi>τ</mi></mfrac></mstyle></mrow></mrow><mo>)</mo></mrow><mrow><msub><mi>log</mi><mi>d</mi></msub><mo lspace="0.167em">⁡</mo><mn>2</mn></mrow></msup></mrow></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mtext>if&#160;</mtext><mrow><mi>d</mi><mo>≠</mo><mn>1</mn></mrow><mtext>.</mtext></mrow></mtd></mtr></mtable></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>

</div></details>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3 </span>Setting the effective compute corresponding to the Automated Coder</h3>

<div id="S1.SS3.p1" class="ltx_para">
<p class="ltx_p">Now that we’ve defined how time horizon progresses as a function of effective compute, we need to translate this into the effective compute required to reach an Automated Coder.</p>
</div>
<div id="S1.SS3.p2" class="ltx_para">
<p class="ltx_p">We first set the time horizon <math id="S1.SS3.p2.m1" class="ltx_Math" alttext="H_{\text{AC}}" display="inline"><msub><mi>H</mi><mtext>AC</mtext></msub></math> required to achieve AC. We set the AC time horizon requirement by estimating the time horizon of tasks that AI company programmers do, adjusting upward because our time horizons only require <math id="S1.SS3.p2.m2" class="ltx_Math" alttext=">80\%" display="inline"><mrow><mi></mi><mo>&gt;</mo><mrow><mn>80</mn><mo>%</mo></mrow></mrow></math> success rate, then adjusting upward again for the difference between the METR-HRS-Extended benchmark and real-world coding tasks.</p>
</div>
<div id="S1.SS3.p3" class="ltx_para">
<p class="ltx_p">Finally, we add an optional “effective compute gap” to our model to represent the possibility that the Automated Coder milestone may come later than when the AC time horizon requirement is achieved (e.g. maybe AIs will saturate METR-HRS-extended without fully replacing a human on real-world coding tasks, in a way that can’t be corrected for by adjusting the required horizon). For simulations of our model that use a gap, we sample the “pre-gap time horizon” from a different distribution than the distribution we use for simulations where the AC effective compute requirement does not use a gap. We do this because the “gap perspective” seems connected to the view that an extended METR-style benchmark would saturate at lower time horizons, compared with the perspective where a high enough time horizon gives an Automated Coder.</p>
</div>
<details><summary id="explicit-formula-for-the-automated-coder-effective-compute-requirement-including-an-optional-effective-compute-gap">Explicit formula for the Automated Coder effective compute requirement, including an (optional) effective compute gap.</summary><div id="S1.SS3.p4" class="ltx_para">

<table id="S1.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S1.Ex4.m1" class="ltx_Math" alttext="\overline{E}_{\text{AC}}=\begin{cases}\overline{E}(\text{present-day})+\frac{%
\tau}{d-1}\left(\left(\frac{H_{\text{AC}}}{H(\text{present-day})}\right)^{\log%
_{2}d}-1\right)+\overline{E}_{\text{gap}}&\text{ if }d\neq 1;\\
\overline{E}(\text{present-day})+\tau\,\log_{2}\!\left(\frac{H_{\text{AC}}}{H(%
\text{present-day})}\right)+\overline{E}_{\text{gap}}&\text{ if }d=1.\end{cases}" display="block"><mrow><msub><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mtext>AC</mtext></msub><mo>=</mo><mrow><mo>{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><mstyle displaystyle="false"><mfrac><mi>τ</mi><mrow><mi>d</mi><mo>−</mo><mn>1</mn></mrow></mfrac></mstyle><mo>⁢</mo><mrow><mo>(</mo><mrow><msup><mrow><mo>(</mo><mstyle displaystyle="false"><mfrac><msub><mi>H</mi><mtext>AC</mtext></msub><mrow><mi>H</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo>)</mo></mrow><mrow><msub><mi>log</mi><mn>2</mn></msub><mo lspace="0.167em">⁡</mo><mi>d</mi></mrow></msup><mo>−</mo><mn>1</mn></mrow><mo>)</mo></mrow></mrow><mo>+</mo><msub><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mtext>gap</mtext></msub></mrow></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mrow><mtext>&#160;if&#160;</mtext><mo>⁢</mo><mi>d</mi></mrow><mo>≠</mo><mn>1</mn></mrow><mo>;</mo></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><mi>τ</mi><mo lspace="0.337em">⁢</mo><mrow><msub><mi>log</mi><mn>2</mn></msub><mo>⁡</mo><mrow><mo>(</mo><mstyle displaystyle="false"><mfrac><msub><mi>H</mi><mtext>AC</mtext></msub><mrow><mi>H</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow><mo>+</mo><msub><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mtext>gap</mtext></msub></mrow></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mrow><mrow><mtext>&#160;if&#160;</mtext><mo>⁢</mo><mi>d</mi></mrow><mo>=</mo><mn>1</mn></mrow><mo lspace="0em">.</mo></mrow></mtd></mtr></mtable></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>

</div></details>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Modeling effective compute</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">In our model, we take into account inputs including human labor, automated labor, training compute, experiment compute, and automation compute. We need some way to aggregate all these inputs together and map them onto concrete capabilties. Given that recent AI progress has been driven in substantial part by scaling up the compute used to train models, we decide to aggregate these inputs into <span class="ltx_text ltx_font_italic">effective compute</span>: a metric that collapses <span class="ltx_text ltx_font_italic">software progress</span>, i.e. more efficiently converting training compute into performance, onto the same axis as training compute. We then model concrete capabilities as functions of effective compute, as described in <a href="#S1.SS3" title="1.3 Setting the effective compute corresponding to the Automated Coder ‣ 1 Time horizon and the Automated Coder milestone" class="ltx_ref">Automated Coder Effective Compute</a>, <a href="#S3" title="3 Coding automation" class="ltx_ref">Coding Automation</a>, and <a href="#S4" title="4 Experiment selection automation" class="ltx_ref">Experiment Selection Automation</a>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">Effective compute <math id="S2.p2.m1" class="ltx_Math" alttext="E(t)" display="inline"><mrow><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is the amount of training compute we’d need to train models as performant as the frontier models at time <math id="S2.p2.m2" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> using the training process of the present-day. We express effective compute as the product of training compute <math id="S2.p2.m3" class="ltx_Math" alttext="C_{\text{train}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>train</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> and <span class="ltx_text ltx_font_italic">software efficiency</span> <math id="S2.p2.m4" class="ltx_Math" alttext="S(t)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>:</p>
<table id="S2.Ex5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex5.m1" class="ltx_Math" alttext="E(t)=C_{\text{train}}(t)\,S(t)." display="block"><mrow><mrow><mrow><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>C</mi><mtext>train</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mo lspace="0.170em">⁢</mo><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">Software efficiency <math id="S2.p2.m5" class="ltx_Math" alttext="S(t)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> measures how compute-efficient the training process at time <math id="S2.p2.m6" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> is. By definition, <math id="S2.p2.m7" class="ltx_Math" alttext="S(\text{present-day})=1" display="inline"><mrow><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mn>1</mn></mrow></math>. And <math id="S2.p2.m8" class="ltx_Math" alttext="S(\text{June 2027})=1000" display="inline"><mrow><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>June 2027</mtext><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mn>1000</mn></mrow></math> would mean: if we used the present-day training process, it would take <math id="S2.p2.m9" class="ltx_math_unparsed" alttext="1000\times" display="inline"><mrow><mn>1000</mn><mo lspace="0.222em">×</mo></mrow></math> more compute than in June 2027 to train models as performant as the best from June 2027.</p>
</div>
<details><summary id="limitations-of-using-effective-compute">Limitations of using effective compute.</summary><div id="S2.p3" class="ltx_para">
<p class="ltx_p">
While effective compute is the best solution we know of for aggregating inputs to AI progress, it bakes in important assumptions, in particular that something like current AI training processes with relatively minor adaptations could scale to very high capabilities. We believe our model is still valuable even if this assumption fails, as one could make definitions of effective compute that allow for more “adaptation labor” and this might lead to similar behavior. But it is certainly harder to interpret the effective compute values without this assumption and our model’s results may be off base because of this.<sup><a href="#fn3" id="fnref3">3</a></sup> <span class="ltx_text" style="color:#FF00FF;">ALEX-SUGGESTION: “Adaptation labor” needs to be clarified.</span>
</p>
</div></details>
<div id="S2.p4" class="ltx_para">
<p class="ltx_p">Our model of the progression of software efficiency <math id="S2.p4.m1" class="ltx_Math" alttext="S(t)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> depends on the variables of <span class="ltx_text ltx_font_italic">experiment throughput</span> and <span class="ltx_text ltx_font_italic">(software) research effort</span>. For clarity of exposition, we discuss these first and how they’re modeled. In <span class="ltx_ref ltx_missing_label ltx_ref_self">Software efficiency</span>, we’ll explain how gains in research effort are converted into gains in software efficiency. Before all that, we say a bit more about the compute data our model uses.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Compute forecasts</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p">In our model we track 3 types of compute:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p class="ltx_p">Training compute <math id="S2.I1.i1.p1.m1" class="ltx_Math" alttext="C_{\text{train}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>train</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>, a direct input to effective compute.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p class="ltx_p">Experiment compute <math id="S2.I1.i2.p1.m1" class="ltx_Math" alttext="C_{\text{xpm}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>xpm</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>, an input to software efficiency.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p class="ltx_p">Automation compute <math id="S2.I1.i3.p1.m1" class="ltx_Math" alttext="C_{\text{aut}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>aut</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>, an input into <a href="#S3" title="3 Coding automation" class="ltx_ref">coding automation</a>.</p>
</div>
</li>
</ol>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p class="ltx_p">These are modeled as exogenous time series, i.e. they don’t change based on what else is going on in the model. This means we aren’t modeling hardware R&amp;D automation, hardware production automation, or economic growth, which is a serious limitation of our model, particularly in slow takeoff scenarios.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p class="ltx_p">We forecast these by doing <span class="ltx_text" style="color:#0000FF;">ELI-TODO: finish this</span>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Experiment throughput</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Experiment throughput</span> <math id="S2.SS2.p1.m1" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> represents the AI project’s capacity for implementing and running experiments. It can roughly be understood as the number of experiments the project manages to implement and run per unit time, where experiments are weighted by how much compute they use and how labor-intensive they are to code.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p class="ltx_p">Experiment throughput is modeled as a function of experiment compute <math id="S2.SS2.p2.m1" class="ltx_Math" alttext="C_{\text{xpm}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>xpm</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> (i.e. the H100-equivalents used to run research experiments) and coding labor <math id="S2.SS2.p2.m2" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> (i.e. the number of full-time-human-equivalent coders). Although experiment throughput goes up with both experiment compute <math id="S2.SS2.p2.m3" class="ltx_Math" alttext="C_{\text{xpm}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>xpm</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> and coding labor <math id="S2.SS2.p2.m4" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>, there are diminishing returns to only increasing one of the inputs and not the other. One way to model this relationship would be to use a Cobb-Douglas function: <math id="S2.SS2.p2.m5" class="ltx_Math" alttext="X(t)=C_{\text{xpm}}(t)^{\alpha}L_{C}(t)^{\beta}" display="inline"><mrow><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>C</mi><mtext>xpm</mtext></msub><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mi>α</mi></msup><mo>⁢</mo><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mi>β</mi></msup></mrow></mrow></math> where <math id="S2.SS2.p2.m6" class="ltx_Math" alttext="0<\alpha<1" display="inline"><mrow><mn>0</mn><mo>&lt;</mo><mi>α</mi><mo>&lt;</mo><mn>1</mn></mrow></math> and <math id="S2.SS2.p2.m7" class="ltx_Math" alttext="0<\beta<1" display="inline"><mrow><mn>0</mn><mo>&lt;</mo><mi>β</mi><mo>&lt;</mo><mn>1</mn></mrow></math>. This has the property that if one of <math id="S2.SS2.p2.m8" class="ltx_Math" alttext="C_{\text{xpm}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>xpm</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> or <math id="S2.SS2.p2.m9" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> becomes much larger than the other, then increases in <math id="S2.SS2.p2.m10" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> come mainly from the smaller input, because the larger input exhibits diminishing returns.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p class="ltx_p">One problem with the Cobb-Douglas function is that experiment throughput can go to infinity when one of <math id="S2.SS2.p3.m1" class="ltx_Math" alttext="C_{\text{xpm}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>xpm</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> or <math id="S2.SS2.p3.m2" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> goes to infinity but the other remains bounded, which isn’t realistic. If you have infinite coding labor but only a fixed amount of experiment compute, you can only implement so many experiments per unit time; and if you have experiment compute but only a fixed number of coders, you don’t have enough workers to code up experiments that (usefully) use the compute.<sup><a href="#fn4" id="fnref4">4</a></sup> In economic terms, we would say that experiment compute and coding labor are complementary inputs that cannot fully substitute for each other. This is often modeled with a CES (“constant elasticity of substitution”) production function with substitution parameter <math id="S2.SS2.p3.m3" class="ltx_Math" alttext="\rho_{X}<0" display="inline"><mrow><msub><mi>ρ</mi><mi>X</mi></msub><mo>&lt;</mo><mn>0</mn></mrow></math> (the rest of the model explanation won’t depend on the mathematical details we discuss here):</p>
<table id="S2.Ex6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex6.m1" class="ltx_Math" alttext="X(t)=\left(\alpha\,\tilde{C}_{\text{xpm}}(t)^{\rho_{X}}+(1-\alpha)\,\tilde{L}_%
{C}(t)^{\rho_{X}}\right)^{1/\rho_{X}},\quad 0<\alpha<1,\;\rho_{X}<0," display="block"><mrow><mrow><mrow><mrow><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><msup><mrow><mo>(</mo><mrow><mrow><mi>α</mi><mo lspace="0.170em">⁢</mo><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mtext>xpm</mtext></msub><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><msub><mi>ρ</mi><mi>X</mi></msub></msup></mrow><mo>+</mo><mrow><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow><mo stretchy="false">)</mo></mrow><mo lspace="0.170em">⁢</mo><msub><mover accent="true"><mi>L</mi><mo>~</mo></mover><mi>C</mi></msub><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><msub><mi>ρ</mi><mi>X</mi></msub></msup></mrow></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><msub><mi>ρ</mi><mi>X</mi></msub></mrow></msup></mrow><mo rspace="1.167em">,</mo><mrow><mn>0</mn><mo>&lt;</mo><mi>α</mi><mo>&lt;</mo><mn>1</mn></mrow></mrow><mo rspace="0.447em">,</mo><mrow><msub><mi>ρ</mi><mi>X</mi></msub><mo>&lt;</mo><mn>0</mn></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">where</p>
<table id="S2.Ex7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex7.m1" class="ltx_Math" alttext="\tilde{C}_{\text{xpm}}(t)=C_{\text{xpm}}(t)^{\zeta},\quad\tilde{L}_{\text{C}}(%
t)=L_{\text{C}}(t)^{\lambda},\quad 0<\zeta<1,\;0<\lambda<1." display="block"><mrow><mrow><mrow><mrow><mrow><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mtext>xpm</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>C</mi><mtext>xpm</mtext></msub><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mi>ζ</mi></msup></mrow></mrow><mo rspace="1.167em">,</mo><mrow><mrow><mrow><msub><mover accent="true"><mi>L</mi><mo>~</mo></mover><mtext>C</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>L</mi><mtext>C</mtext></msub><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mi>λ</mi></msup></mrow></mrow><mo rspace="1.167em">,</mo><mrow><mn>0</mn><mo>&lt;</mo><mi>ζ</mi><mo>&lt;</mo><mn>1</mn></mrow></mrow></mrow><mo>,</mo><mrow><mn> 0</mn><mo>&lt;</mo><mi>λ</mi><mo>&lt;</mo><mn>1</mn></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">What is <math id="S2.SS2.p4.m1" class="ltx_Math" alttext="\alpha" display="inline"><mi>α</mi></math>?</span> The closer <math id="S2.SS2.p4.m2" class="ltx_Math" alttext="0<\alpha<1" display="inline"><mrow><mn>0</mn><mo>&lt;</mo><mi>α</mi><mo>&lt;</mo><mn>1</mn></mrow></math> is to <math id="S2.SS2.p4.m3" class="ltx_Math" alttext="1" display="inline"><mn>1</mn></math>, the more experiment compute is considered important relative to coding labor.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">What is <math id="S2.SS2.p5.m1" class="ltx_Math" alttext="\rho_{X}" display="inline"><msub><mi>ρ</mi><mi>X</mi></msub></math>?</span> The smaller <math id="S2.SS2.p5.m2" class="ltx_Math" alttext="\rho_{X}<0" display="inline"><mrow><msub><mi>ρ</mi><mi>X</mi></msub><mo>&lt;</mo><mn>0</mn></mrow></math> is, the less it’s possible to only increase one of <math id="S2.SS2.p5.m3" class="ltx_Math" alttext="C_{\text{xpm}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>xpm</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> and <math id="S2.SS2.p5.m4" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> in order to increase <math id="S2.SS2.p5.m5" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>. The CES expression has the property that: if we fix <math id="S2.SS2.p5.m6" class="ltx_Math" alttext="C_{\text{xpm}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>xpm</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> and take <math id="S2.SS2.p5.m7" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> to infinity, then <math id="S2.SS2.p5.m8" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> will asymptote to <math id="S2.SS2.p5.m9" class="ltx_Math" alttext="\alpha^{1/\rho}\tilde{C}_{\text{xpm}}(t)" display="inline"><mrow><msup><mi>α</mi><mrow><mn>1</mn><mo>/</mo><mi>ρ</mi></mrow></msup><mo>⁢</mo><msub><mover accent="true"><mi>C</mi><mo>~</mo></mover><mtext>xpm</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>; and if we fix <math id="S2.SS2.p5.m10" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> and take <math id="S2.SS2.p5.m11" class="ltx_Math" alttext="C_{\text{xpm}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>xpm</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> to infinity, then <math id="S2.SS2.p5.m12" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> will asymptote to <math id="S2.SS2.p5.m13" class="ltx_Math" alttext="(1-\alpha)^{1/\rho}\tilde{L}_{C}(t)" display="inline"><mrow><msup><mrow><mo stretchy="false">(</mo><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mi>ρ</mi></mrow></msup><mo>⁢</mo><msub><mover accent="true"><mi>L</mi><mo>~</mo></mover><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>. In simple terms, when <math id="S2.SS2.p5.m14" class="ltx_Math" alttext="\rho_{X}<0" display="inline"><mrow><msub><mi>ρ</mi><mi>X</mi></msub><mo>&lt;</mo><mn>0</mn></mrow></math> is small, the maximum possible boost you can get from increasing one of experiment compute or coding labor to infinity is lower.</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">What is <math id="S2.SS2.p6.m1" class="ltx_Math" alttext="\lambda" display="inline"><mi>λ</mi></math>?</span> We use the smaller quantity <math id="S2.SS2.p6.m2" class="ltx_Math" alttext="L_{C}(t)^{\lambda}" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mi>λ</mi></msup></mrow></math> instead of <math id="S2.SS2.p6.m3" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> since <math id="S2.SS2.p6.m4" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is a measure of <span class="ltx_text ltx_font_italic">parallel</span> coding labor but we want a measure of <span class="ltx_text ltx_font_italic">serial</span> coding labor (a single programmer can make more progress in two days than a team of two programmers can make in a day because of the “stepping on toes” effect). The reason we use serial (rather than parallel) coding labor in the CES function is that if the project had unlimited experiment compute, the way we double experiment throughput is by letting the coding workforce work for twice as long (or speeding up the coding workforce by <math id="S2.SS2.p6.m5" class="ltx_math_unparsed" alttext="2\times" display="inline"><mrow><mn>2</mn><mo lspace="0.222em">×</mo></mrow></math>), rather than doubling the size of the coding workforce.</p>
</div>
<div id="S2.SS2.p7" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">What is <math id="S2.SS2.p7.m1" class="ltx_Math" alttext="\zeta" display="inline"><mi>ζ</mi></math>?</span> The reason we discount experiment compute by the exponent <math id="S2.SS2.p7.m2" class="ltx_Math" alttext="0<\zeta<1" display="inline"><mrow><mn>0</mn><mo>&lt;</mo><mi>ζ</mi><mo>&lt;</mo><mn>1</mn></mrow></math> is that, if one had unlimited coding labor, doubling experiment compute doesn’t double experiment throughput because model size increases, meaning the ability to run near-frontier experiments goes down.</p>
</div>
<div id="S2.SS2.p8" class="ltx_para">
<p class="ltx_p">We set the parameter values as follows:</p>
<ol id="S2.I2" class="ltx_enumerate">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p class="ltx_p"><math id="S2.I2.i1.p1.m1" class="ltx_Math" alttext="\lambda" display="inline"><mi>λ</mi></math>: We estimated this based on our intuitions about the effect of increased parallel labor on research effort, as well as interviews with frontier AI researchers.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p class="ltx_p"><math id="S2.I2.i2.p1.m1" class="ltx_Math" alttext="\zeta,\alpha,\rho_{X}" display="inline"><mrow><mi>ζ</mi><mo>,</mo><mi>α</mi><mo>,</mo><msub><mi>ρ</mi><mi>X</mi></msub></mrow></math>: We estimated three quantities, from a fixed starting point of 2024, that together pin down the values of <math id="S2.I2.i2.p1.m2" class="ltx_Math" alttext="\zeta" display="inline"><mi>ζ</mi></math>, <math id="S2.I2.i2.p1.m3" class="ltx_Math" alttext="\alpha" display="inline"><mi>α</mi></math>, and <math id="S2.I2.i2.p1.m4" class="ltx_Math" alttext="\rho_{X}" display="inline"><msub><mi>ρ</mi><mi>X</mi></msub></math>: (a) the decrease in <math id="S2.I2.i2.p1.m5" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> from a <math id="S2.I2.i2.p1.m6" class="ltx_math_unparsed" alttext="10\times" display="inline"><mrow><mn>10</mn><mo lspace="0.222em">×</mo></mrow></math> decrease in <math id="S2.I2.i2.p1.m7" class="ltx_Math" alttext="C_{\text{xpm}}" display="inline"><msub><mi>C</mi><mtext>xpm</mtext></msub></math>, (b) the <math id="S2.I2.i2.p1.m8" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> asymptote as we take <math id="S2.I2.i2.p1.m9" class="ltx_Math" alttext="C_{\text{xpm}}" display="inline"><msub><mi>C</mi><mtext>xpm</mtext></msub></math> to infinity, and (c) the <math id="S2.I2.i2.p1.m10" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> asymptote as we take <math id="S2.I2.i2.p1.m11" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> to infinity. To estimate these quantities, we combined frontier AI researcher interviews, surveys of other AI experts, and our own reasoning about how <math id="S2.I2.i2.p1.m12" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> would change given infinite coding labor or compute.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Software research effort and AI R&amp;D uplift</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p class="ltx_p">Research effort <math id="S2.SS3.p1.m1" class="ltx_Math" alttext="RE(t)" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is the number of <span class="ltx_text ltx_font_italic">quality-adjusted</span> experiments the project can perform per unit time. That is, it’s a version of experiment throughput <math id="S2.SS3.p1.m2" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> but where experiments proposed by more skillful researchers are weighted more (experiment throughput only weighted experiments by the amount of experiment compute they required and how much coding labor they required to be implemented).</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p class="ltx_p">We model research effort <math id="S2.SS3.p2.m1" class="ltx_Math" alttext="RE(t)" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> as the product of experiment throughput <math id="S2.SS3.p2.m2" class="ltx_Math" alttext="X(t)" display="inline"><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> and <span class="ltx_text ltx_font_italic">aggregate experiment selection skill</span> <math id="S2.SS3.p2.m3" class="ltx_Math" alttext="T(t)" display="inline"><mrow><mi>T</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> (“<math id="S2.SS3.p2.m4" class="ltx_Math" alttext="T" display="inline"><mi>T</mi></math>” for “taste”):</p>
<table id="S2.Ex8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex8.m1" class="ltx_math_unparsed" alttext="RE(t)=T(t)\,X(t.)" display="block"><mrow><mi>R</mi><mi>E</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mo>=</mo><mi>T</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo rspace="0.170em" stretchy="false">)</mo></mrow><mi>X</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mo lspace="0em" rspace="0.167em">.</mo><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">Intuitively, <math id="S2.SS3.p2.m5" class="ltx_Math" alttext="T(t)" display="inline"><mrow><mi>T</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> measures the average value per experiment. For example, if researcher A has <math id="S2.SS3.p2.m6" class="ltx_math_unparsed" alttext="2\times" display="inline"><mrow><mn>2</mn><mo lspace="0.222em">×</mo></mrow></math> the experiment selection skill of researcher B, this means an experiment proposed by A is as valuable as two experiments proposed by B (assuming all three of these experiments are compute-equivalent and coding-labor-equivalent). For how experiment selection skill is calculated, see <span class="ltx_ref ltx_missing_label ltx_ref_self">Aggregate experiment selection skill</span>.</p>
</div>
<figure id="S2.SS3.fig1" class="ltx_figure"><img src="latex/Research_effort.png" id="S2.SS3.g1" class="ltx_graphics ltx_img_square" width="359" height="352" alt="[Uncaptioned image]">
</figure>
<div id="S2.SS3.p3" class="ltx_para">
<p class="ltx_p">Related to research effort, we track <span class="ltx_text ltx_font_italic">AI software R&amp;D uplift</span> for each time <math id="S2.SS3.p3.m1" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> (called “AI software R&amp;D progress multiplier” in our previous work). This concept is what it sounds like: it measures “how much faster R&amp;D goes with the AIs compared with without the AIs”. Write <math id="S2.SS3.p3.m2" class="ltx_Math" alttext="RE(\text{AI}_{t}\rightarrow\text{present-day})" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mtext>AI</mtext><mi>t</mi></msub><mo stretchy="false">→</mo><mtext>present-day</mtext></mrow><mo stretchy="false">)</mo></mrow></mrow></math> for what research effort would be in the present-day if we magically transported the AIs from time <math id="S2.SS3.p3.m3" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> back to the present-day. Then AI software R&amp;D uplift is:<sup><a href="#fn5" id="fnref5">5</a></sup></p>
<table id="S2.Ex9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex9.m1" class="ltx_Math" alttext="\frac{RE(\text{AI}_{t}\rightarrow\text{present-day})}{RE(\text{present-day})}." display="block"><mrow><mfrac><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><msub><mtext>AI</mtext><mi>t</mi></msub><mo stretchy="false">→</mo><mtext>present-day</mtext></mrow><mo stretchy="false">)</mo></mrow></mrow><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow></mfrac><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Software efficiency</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p class="ltx_p">Recall that software efficiency, <math id="S2.SS4.p1.m1" class="ltx_Math" alttext="S(t)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>, measures how efficiently the training process at time <math id="S2.SS4.p1.m2" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> can convert training compute into performance. We have <math id="S2.SS4.p1.m3" class="ltx_Math" alttext="S(\text{present-day})=1" display="inline"><mrow><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mn>1</mn></mrow></math>, and <math id="S2.SS4.p1.m4" class="ltx_Math" alttext="S(\text{June 2027})=1000" display="inline"><mrow><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>June 2027</mtext><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mn>1000</mn></mrow></math> would mean: if we used the training process of the present-day, it would take <math id="S2.SS4.p1.m5" class="ltx_math_unparsed" alttext="1000\times" display="inline"><mrow><mn>1000</mn><mo lspace="0.222em">×</mo></mrow></math> more compute than in June 2027 to train models as performant as the best from June 2027.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p class="ltx_p">We want to understand how <math id="S2.SS4.p2.m1" class="ltx_Math" alttext="S(t)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> changes as research effort <math id="S2.SS4.p2.m2" class="ltx_Math" alttext="RE(t)" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> changes. Technically though, <math id="S2.SS4.p2.m3" class="ltx_Math" alttext="S" display="inline"><mi>S</mi></math> is not a function of <math id="S2.SS4.p2.m4" class="ltx_Math" alttext="RE" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi></mrow></math> (which is a measure of how “fast” the AI project is going), but of how much total work has actually been done so far. So define the research stock, <math id="S2.SS4.p2.m5" class="ltx_Math" alttext="RS(t)" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>, to be the <span class="ltx_text ltx_font_italic">total</span> amount of research effort done by time <math id="S2.SS4.p2.m6" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>; in symbols,</p>
<table id="S2.Ex10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex10.m1" class="ltx_Math" alttext="RS(t)=\int_{-\infty}^{t}RE(\tau)\,d\tau." display="block"><mrow><mrow><mrow><mi>R</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo rspace="0.111em">=</mo><mrow><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi>t</mi></msubsup><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow><mo lspace="0.170em">⁢</mo><mrow><mo rspace="0em">𝑑</mo><mi>τ</mi></mrow></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">So research stock is to research effort what distance traveled is to speed.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p class="ltx_p">Both research stock and software efficiency describe “how far” the AI project has come, but research stock (like research effort) is about effort/investment while software efficiency is about fruits/returns. We want to know their relationship:</p>
<table id="S2.Ex11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex11.m1" class="ltx_Math" alttext="\text{$RS\approx$ total AI software R\&D work done}\quad\xrightarrow{\text{%
relationship?}}\quad\text{$S\approx$ total returns}" display="block"><mrow><mrow><mrow><mrow><mi>R</mi><mo>⁢</mo><mi>S</mi></mrow><mo>≈</mo><mi></mi></mrow><mtext>&#160;total AI software R&amp;D work done</mtext></mrow><mspace width="1em"></mspace><mover accent="true"><mo stretchy="false">→</mo><mtext>relationship?</mtext></mover><mspace width="1em"></mspace><mrow><mrow><mi>S</mi><mo>≈</mo><mi></mi></mrow><mtext>&#160;total returns</mtext></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS4.p4" class="ltx_para">
<p class="ltx_p">When we look at past empirical data, we see that <math id="S2.SS4.p4.m1" class="ltx_Math" alttext="S(t)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> has been growing exponentially over time. Meanwhile research effort and research stock should also be growing exponentially, since both experiment compute and AI software R&amp;D labor have been growing exponentially over the last 10 years. So, since <math id="S2.SS4.p4.m2" class="ltx_Math" alttext="S(t)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> and <math id="S2.SS4.p4.m3" class="ltx_Math" alttext="RS(t)" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> both grow exponentially over time (with different bases for the exponentials), the relationship between them is best modeled by a power law:</p>
<table id="S2.Ex12" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex12.m1" class="ltx_Math" alttext="S(t)=C\cdot RS(t)^{1/\beta},\quad\text{for some fixed parameters $C$ and $%
\beta>0$}." display="block"><mrow><mrow><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><mi>C</mi><mo lspace="0.222em" rspace="0.222em">⋅</mo><mi>R</mi></mrow><mo>⁢</mo><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mi>β</mi></mrow></msup></mrow><mo rspace="1.167em">,</mo><mrow><mtext>for some fixed parameters&#160;</mtext><mi>C</mi><mtext>&#160;and&#160;</mtext><mrow><mi>β</mi><mo>&gt;</mo><mn>0</mn></mrow></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">Intuitively:</p>
<table id="S2.Ex13" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex13.m1" class="ltx_Math" alttext="\text{$\beta$ doublings of research stock $RS$}\quad\xrightarrow{\text{%
produces}}\quad\text{1 doubling of software efficiency $S$}" display="block"><mrow><mrow><mi>β</mi><mtext>&#160;doublings of research stock&#160;</mtext><mrow><mi>R</mi><mo>⁢</mo><mi>S</mi></mrow></mrow><mspace width="1em"></mspace><mover accent="true"><mo stretchy="false">→</mo><mtext>produces</mtext></mover><mspace width="1em"></mspace><mrow><mtext>1 doubling of software efficiency&#160;</mtext><mi>S</mi></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS4.p5" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Diminishing returns</span>: AI capabilities come from a combination of software efficiency <math id="S2.SS4.p5.m1" class="ltx_Math" alttext="S" display="inline"><mi>S</mi></math> and training compute <math id="S2.SS4.p5.m2" class="ltx_Math" alttext="C_{\text{train}}" display="inline"><msub><mi>C</mi><mtext>train</mtext></msub></math>. Since training compute has been growing exponentially, for <math id="S2.SS4.p5.m3" class="ltx_Math" alttext="S" display="inline"><mi>S</mi></math> to “keep up” and not fade into irrelevance, it also needs to be growing exponentially. So it’s natural to talk about returns on research effort in terms of <math id="S2.SS4.p5.m4" class="ltx_Math" alttext="\overline{S}=\log S" display="inline"><mrow><mover accent="true"><mi>S</mi><mo>¯</mo></mover><mo>=</mo><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mi>S</mi></mrow></mrow></math> (i.e. orders of magnitude of <math id="S2.SS4.p5.m5" class="ltx_Math" alttext="S" display="inline"><mi>S</mi></math>). Since</p>
<table id="S2.Ex14" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex14.m1" class="ltx_Math" alttext="\overline{S}=\log C+\frac{1}{\beta}\cdot\log RS\approx\frac{1}{\beta}\cdot\log
RS," display="block"><mrow><mrow><mover accent="true"><mi>S</mi><mo>¯</mo></mover><mo>=</mo><mrow><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mi>C</mi></mrow><mo>+</mo><mrow><mfrac><mn>1</mn><mi>β</mi></mfrac><mo lspace="0.222em" rspace="0.222em">⋅</mo><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mrow><mi>R</mi><mo>⁢</mo><mi>S</mi></mrow></mrow></mrow></mrow><mo>≈</mo><mrow><mfrac><mn>1</mn><mi>β</mi></mfrac><mo lspace="0.222em" rspace="0.222em">⋅</mo><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mrow><mi>R</mi><mo>⁢</mo><mi>S</mi></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">successive equal-sized increases in <math id="S2.SS4.p5.m6" class="ltx_Math" alttext="RS" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>S</mi></mrow></math> lead to smaller and smaller increases in <math id="S2.SS4.p5.m7" class="ltx_Math" alttext="\overline{S}" display="inline"><mover accent="true"><mi>S</mi><mo>¯</mo></mover></math> over time. This is the phenomenon of “diminishing returns”: the more progress has already been made, the harder it becomes to make impactful new discoveries since the low-hanging fruits have been picked.</p>
</div>
<figure id="S2.SS4.fig1" class="ltx_figure"><img src="latex/diminishing_returns.png" id="S2.SS4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="432" alt="[Uncaptioned image]">
</figure>
<details><summary id="connection-to-the-jones-semi-endogenous-growth-model">Connection to the Jones semi-endogenous growth model</summary><div id="S2.SS4.p7" class="ltx_para">
<p class="ltx_p">Jones 1995 uses the following growth law to model idea production:</p>
<table id="S2.Ex15" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex15.m1" class="ltx_Math" alttext="A^{\prime}(t)=a\,A(t)^{1-\beta}\,R(t)^{\lambda}." display="block"><mrow><mrow><mrow><msup><mi>A</mi><mo>′</mo></msup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>a</mi><mo lspace="0.170em">⁢</mo><mi>A</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>−</mo><mi>β</mi></mrow></msup><mo>⁢</mo><mi>R</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mi>λ</mi></msup></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">Here <math id="S2.SS4.p7.m1" class="ltx_Math" alttext="A(t)" display="inline"><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is the stock of ideas and <math id="S2.SS4.p7.m2" class="ltx_Math" alttext="R(t)" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is the number of researchers engaged in idea production. The parameter <math id="S2.SS4.p7.m3" class="ltx_Math" alttext="\lambda>0" display="inline"><mrow><mi>λ</mi><mo>&gt;</mo><mn>0</mn></mrow></math> controls the “stepping on toes” effect from adding additional researchers, and <math id="S2.SS4.p7.m4" class="ltx_Math" alttext="\beta>0" display="inline"><mrow><mi>β</mi><mo>&gt;</mo><mn>0</mn></mrow></math> represents the strength of the “fishing out” effect, according to which ideas become harder to find as the stock grows.</p>
</div><div id="S2.SS4.p8" class="ltx_para">
<p class="ltx_p">In past AGI takeoff models (e.g., <a href="https://takeoffspeeds.com/description.html" title="" class="ltx_ref ltx_href">Davidson’s FTM model</a> and <a href="https://epoch.ai/gate" title="" class="ltx_ref ltx_href">Epoch’s GATE model</a>), software efficiency <math id="S2.SS4.p8.m1" class="ltx_Math" alttext="S(t)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> replaced the stock of ideas <math id="S2.SS4.p8.m2" class="ltx_Math" alttext="A(t)" display="inline"><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>. All proposed models have had the form</p>
<table id="S2.Ex16" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex16.m1" class="ltx_Math" alttext="S^{\prime}(t)=a\,S(t)^{1-\beta}\,RE(t)," display="block"><mrow><mrow><mrow><msup><mi>S</mi><mo>′</mo></msup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>a</mi><mo lspace="0.170em">⁢</mo><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>−</mo><mi>β</mi></mrow></msup><mo>⁢</mo><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">for various definitions of research effort <math id="S2.SS4.p8.m3" class="ltx_Math" alttext="RE(t)" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>.</p>
</div><div id="S2.SS4.p9" class="ltx_para">
<p class="ltx_p">We show this growth law reduces to our formula <math id="S2.SS4.p9.m1" class="ltx_Math" alttext="S(t)=C\cdot RS(t)^{1/\beta}" display="inline"><mrow><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>C</mi><mo lspace="0.222em" rspace="0.222em">⋅</mo><mi>R</mi></mrow><mo>⁢</mo><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mi>β</mi></mrow></msup></mrow></mrow></math> from above. We have:</p>
<table id="S5.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.Ex17"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex17.m1" class="ltx_Math" alttext="\displaystyle RS(t)" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex17.m2" class="ltx_Math" alttext="\displaystyle=\int_{-\infty}^{t}RE(\tau)\,d\tau=\frac{1}{a}\int_{-\infty}^{t}%
\frac{S^{\prime}(\tau)}{S(\tau)^{1-\beta}}d\tau." display="inline"><mrow><mrow><mi></mi><mo>=</mo><mrow><mstyle displaystyle="true"><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi>t</mi></msubsup></mstyle><mrow><mi>R</mi><mo>⁢</mo><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow><mo lspace="0.170em">⁢</mo><mrow><mo rspace="0em">𝑑</mo><mi>τ</mi></mrow></mrow></mrow><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mi>a</mi></mfrac></mstyle><mo>⁢</mo><mrow><mstyle displaystyle="true"><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi>t</mi></msubsup></mstyle><mrow><mstyle displaystyle="true"><mfrac><mrow><msup><mi>S</mi><mo>′</mo></msup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow></mrow><mrow><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>−</mo><mi>β</mi></mrow></msup></mrow></mfrac></mstyle><mo lspace="0em">⁢</mo><mrow><mo rspace="0em">𝑑</mo><mi>τ</mi></mrow></mrow></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody><tr class="ltx_eqn_row ltx_align_baseline"><td class="ltx_eqn_cell ltx_align_left" style="white-space:normal;" colspan="5">The integral on the right can be computed via the substitution <math id="S5.EGx1.m1" class="ltx_Math" alttext="U=S(\tau)^{\beta}" display="inline"><mrow><mi>U</mi><mo>=</mo><mrow><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow><mi>β</mi></msup></mrow></mrow></math>, <math id="S5.EGx1.m2" class="ltx_Math" alttext="dU=\frac{\beta S^{\prime}(\tau)}{S(\tau)^{1-\beta}}d\tau" display="inline"><mrow><mrow><mi>d</mi><mo>⁢</mo><mi>U</mi></mrow><mo>=</mo><mrow><mfrac><mrow><mi>β</mi><mo>⁢</mo><msup><mi>S</mi><mo>′</mo></msup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow></mrow><mrow><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>−</mo><mi>β</mi></mrow></msup></mrow></mfrac><mo>⁢</mo><mi>d</mi><mo>⁢</mo><mi>τ</mi></mrow></mrow></math>:</td></tr></tbody>
<tbody id="S2.Ex18"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex18.m1" class="ltx_Math" alttext="\displaystyle RS(t)" display="inline"><mrow><mi>R</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex18.m2" class="ltx_Math" alttext="\displaystyle=\frac{1}{a}\int_{-\infty}^{t}\frac{S^{\prime}(\tau)}{S(\tau)^{1-%
\beta}}d\tau" display="inline"><mrow><mi></mi><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mi>a</mi></mfrac></mstyle><mo>⁢</mo><mrow><mstyle displaystyle="true"><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi>t</mi></msubsup></mstyle><mrow><mstyle displaystyle="true"><mfrac><mrow><msup><mi>S</mi><mo>′</mo></msup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow></mrow><mrow><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>τ</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>−</mo><mi>β</mi></mrow></msup></mrow></mfrac></mstyle><mo lspace="0em">⁢</mo><mrow><mo rspace="0em">𝑑</mo><mi>τ</mi></mrow></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex19"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex19.m1" class="ltx_Math" alttext="\displaystyle=\frac{1}{a\beta}\left(S(t)^{\beta}-S(-\infty)^{\beta}\right)" display="inline"><mrow><mi></mi><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><mi>a</mi><mo>⁢</mo><mi>β</mi></mrow></mfrac></mstyle><mo>⁢</mo><mrow><mo>(</mo><mrow><mrow><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mi>β</mi></msup></mrow><mo>−</mo><mrow><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mo stretchy="false">)</mo></mrow><mi>β</mi></msup></mrow></mrow><mo>)</mo></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex20"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex20.m1" class="ltx_Math" alttext="\displaystyle=\frac{1}{a\beta}S(t)^{\beta}." display="inline"><mrow><mrow><mi></mi><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><mi>a</mi><mo>⁢</mo><mi>β</mi></mrow></mfrac></mstyle><mo>⁢</mo><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mi>β</mi></msup></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody><tr class="ltx_eqn_row ltx_align_baseline"><td class="ltx_eqn_cell ltx_align_left" style="white-space:normal;" colspan="5">Solving for <math id="S5.EGx1.m3" class="ltx_Math" alttext="S(t)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>,</td></tr></tbody>
<tbody id="S2.Ex21"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex21.m1" class="ltx_Math" alttext="\displaystyle S(t)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex21.m2" class="ltx_Math" alttext="\displaystyle=\left(a\beta\right)^{1/\beta}RS(t)^{1/\beta}=C\cdot RS(t)^{1/%
\beta},\quad\quad\quad\text{for $C=\left(a\beta\right)^{1/\beta}$}." display="inline"><mrow><mrow><mrow><mi></mi><mo>=</mo><mrow><msup><mrow><mo>(</mo><mrow><mi>a</mi><mo>⁢</mo><mi>β</mi></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mi>β</mi></mrow></msup><mo>⁢</mo><mi>R</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mi>β</mi></mrow></msup></mrow><mo>=</mo><mrow><mrow><mi>C</mi><mo lspace="0.222em" rspace="0.222em">⋅</mo><mi>R</mi></mrow><mo>⁢</mo><mi>S</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mi>β</mi></mrow></msup></mrow></mrow><mo rspace="3.167em">,</mo><mrow><mtext>for&#160;</mtext><mrow><mi>C</mi><mo>=</mo><msup><mrow><mo>(</mo><mrow><mi>a</mi><mo>⁢</mo><mi>β</mi></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><mi>β</mi></mrow></msup></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>

</div></details>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Coding automation</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">We now turn to describing how our model sets AIs’ R&amp;D capabilities and how that affects the inputs to software research effort.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Coding automation fraction</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">We think coding is reasonably well described as a stable set of types of tasks, and that some tasks will be (or already are) automatable far before others. We define the <span class="ltx_text ltx_font_italic">coding automation fraction</span> <math id="S3.SS1.p1.m1" class="ltx_Math" alttext="A(t)" display="inline"><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> to be the fraction of coding work (involved in frontier AI research) that can be efficiently automated. For example, <math id="S3.SS1.p1.m2" class="ltx_Math" alttext="A(\text{March 2029})=80\%" display="inline"><mrow><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>March 2029</mtext><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mn>80</mn><mo>%</mo></mrow></mrow></math> means that we could use the AIs of March 2029 to automate away <math id="S3.SS1.p1.m3" class="ltx_Math" alttext="80\%" display="inline"><mrow><mn>80</mn><mo>%</mo></mrow></math> of the coding work done in the present-day and not lose in productivity (<math id="S3.SS1.p1.m4" class="ltx_Math" alttext="80\%" display="inline"><mrow><mn>80</mn><mo>%</mo></mrow></math> as measured by the proportion of clone-parity coders doing that work; see the expandable box below).</p>
</div>
<details><summary id="when-is-a-task-considered-efficiently-automatable">When is a task considered efficiently automatable?</summary><div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p"> We define a “clone-parity coder” by the condition that, if every human coder were replaced by a clone-parity coder, productivity would remain the same. For each type of coding task, we weight its importance by how many clone-parity coders would work on the task absent AI assistance. We consider a task efficiently automatable when AIs can complete the task faster than the human coders and using no more than <math id="S3.SS1.p2.m1" class="ltx_Math" alttext="\frac{B}{N}" display="inline"><mfrac><mi>B</mi><mi>N</mi></mfrac></math> of present-day automation compute, where <math id="S3.SS1.p2.m2" class="ltx_Math" alttext="B" display="inline"><mi>B</mi></math> is the number of human clone-parity-coder-equivalents working on the task in the present-day and <math id="S3.SS1.p2.m3" class="ltx_Math" alttext="N" display="inline"><mi>N</mi></math> is the total number of human coders in the present-day. </p>
</div></details>
<div id="S3.SS1.p3" class="ltx_para">
<p class="ltx_p">Our definition of the Automated Coder milestone does not technically imply that <math id="S3.SS1.p3.m1" class="ltx_Math" alttext="A(t_{\text{AC}})=1" display="inline"><mrow><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><msub><mi>t</mi><mtext>AC</mtext></msub><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mn>1</mn></mrow></math> at the time <math id="S3.SS1.p3.m2" class="ltx_Math" alttext="t_{\text{AC}}" display="inline"><msub><mi>t</mi><mtext>AC</mtext></msub></math> when the milestone is reached. Nevertheless, we will make the simplifying assumption that this is the case.</p>
</div>
<details><summary id="why-doesnt-the-definition-of-ac-literally-imply-all-tasks-are-efficiently-automatable">Why doesn’t the definition of AC literally imply all tasks are efficiently automatable?</summary><div id="S3.SS1.p4" class="ltx_para">
<p class="ltx_p"> The Automated Coder (AC) milestone was defined by the condition that if the AC was dropped into the present day, it would overall be as productive as all present-day human coders with no AI assistance. This can be true even if it’s still less efficient than humans for <span class="ltx_text ltx_font_italic">some</span> proportion of tasks. </p>
</div></details>
<div id="S3.SS1.p5" class="ltx_para">
<p class="ltx_p">We model coding automation fraction <math id="S3.SS1.p5.m1" class="ltx_Math" alttext="A(t)" display="inline"><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> as a linear function of OOMs (orders of magnitude) of effective compute <math id="S3.SS1.p5.m2" class="ltx_Math" alttext="\overline{E}(t)=\log E(t)" display="inline"><mrow><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>log</mi><mo lspace="0.167em">⁡</mo><mi>E</mi></mrow><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></math>. That is, we estimate the automation fraction <math id="S3.SS1.p5.m3" class="ltx_Math" alttext="A(\text{present-day})" display="inline"><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow></math> in the present, and let <math id="S3.SS1.p5.m4" class="ltx_Math" alttext="A(t)" display="inline"><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> vary linearly as a function of <math id="S3.SS1.p5.m5" class="ltx_Math" alttext="\overline{E}(t)" display="inline"><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> until <math id="S3.SS1.p5.m6" class="ltx_Math" alttext="A(t)" display="inline"><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> reaches 1 when <math id="S3.SS1.p5.m7" class="ltx_Math" alttext="\overline{E}(t)" display="inline"><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> equals the effective compute <math id="S3.SS1.p5.m8" class="ltx_Math" alttext="\overline{E}_{\text{AC}}" display="inline"><msub><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mtext>AC</mtext></msub></math> for the Automated Coder anchor. So:</p>
<table id="S3.Ex22" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span class="ltx_text ltx_markedasmath"><math id="S3.Ex22.m1.m1" class="ltx_Math" alttext="\overline{E}(t)" display="inline"><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is <math id="S3.Ex22.m1.m2" class="ltx_Math" alttext="y\%" display="inline"><mrow><mi>y</mi><mo>%</mo></mrow></math> of the way between <math id="S3.Ex22.m1.m3" class="ltx_Math" alttext="\overline{E}(\text{present-day})" display="inline"><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow></math> and <math id="S3.Ex22.m1.m4" class="ltx_Math" alttext="\overline{E}_{\text{AC}}" display="inline"><msub><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mtext>AC</mtext></msub></math></span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S3.Ex23" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex23.m1" class="ltx_Math" alttext="\downarrow" display="block"><mo stretchy="false">↓</mo></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S3.Ex24" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex24.m1" class="ltx_Math" alttext="\text{$A(t)$ is $y\%$ of the way between $A(\text{present-day})$ and $1$}." display="block"><mrow><mrow><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mtext>&#160;is&#160;</mtext><mrow><mi>y</mi><mo>%</mo></mrow><mtext>&#160;of the way between&#160;</mtext><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mtext>present-day</mtext><mo stretchy="false">)</mo></mrow></mrow><mtext>&#160;and&#160;</mtext><mn>1</mn></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Coding automation efficiency</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">We use indices <math id="S3.SS2.p1.m1" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> in the interval <math id="S3.SS2.p1.m2" class="ltx_Math" alttext="[0,1]" display="inline"><mrow><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></math> to represent the various coding tasks involved in implementing research experiments. At any given time <math id="S3.SS2.p1.m3" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>, tasks <math id="S3.SS2.p1.m4" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> such that <math id="S3.SS2.p1.m5" class="ltx_Math" alttext="0\leq i\leq A(t)" display="inline"><mrow><mn>0</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></math> are considered efficiently automatable, while tasks <math id="S3.SS2.p1.m6" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> such that <math id="S3.SS2.p1.m7" class="ltx_Math" alttext="A(t)<i\leq 1" display="inline"><mrow><mrow><mi>A</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>&lt;</mo><mi>i</mi><mo>≤</mo><mn>1</mn></mrow></math> are not.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p">For each task <math id="S3.SS2.p2.m1" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>, the coding automation efficiency <math id="S3.SS2.p2.m2" class="ltx_Math" alttext="\eta_{i}(t)" display="inline"><mrow><msub><mi>η</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is the conversion rate between units of automation compute (i.e. H100-equivalents) and the equivalent in human coders. In other words, if <math id="S3.SS2.p2.m3" class="ltx_Math" alttext="C_{\text{aut},i}(t)" display="inline"><mrow><msub><mi>C</mi><mrow><mtext>aut</mtext><mo>,</mo><mi>i</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is the amount of compute assigned to task <math id="S3.SS2.p2.m4" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>, then this corresponds to having <math id="S3.SS2.p2.m5" class="ltx_Math" alttext="\eta_{i}(t)\,C_{\text{aut},i}(t)" display="inline"><mrow><msub><mi>η</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><mo lspace="0.170em">⁢</mo><msub><mi>C</mi><mrow><mtext>aut</mtext><mo>,</mo><mi>i</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> additional human coders work on task <math id="S3.SS2.p2.m6" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>. So <math id="S3.SS2.p2.m7" class="ltx_Math" alttext="\eta_{i}(t)" display="inline"><mrow><msub><mi>η</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is a measure of the runtime efficiency of AIs for task <math id="S3.SS2.p2.m8" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>; efficiency gains come from a combination of making AIs faster, being able to run more AIs, and getting more capable AIs that can complete tasks with fewer actions.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p class="ltx_p">Writing <math id="S3.SS2.p3.m1" class="ltx_Math" alttext="E_{i}" display="inline"><msub><mi>E</mi><mi>i</mi></msub></math> for the effective compute corresponding to when task <math id="S3.SS2.p3.m2" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> is first efficiently automatable, our model for <math id="S3.SS2.p3.m3" class="ltx_Math" alttext="\eta_{i}(t)" display="inline"><mrow><msub><mi>η</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is:</p>
<table id="S3.Ex25" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex25.m1" class="ltx_Math" alttext="\eta_{i}(t)=\begin{cases}\eta_{\text{init}}\cdot\left(\frac{E(t)}{E_{i}}\right%
)^{\eta_{\text{slope}}}&\text{if task $i$ is efficiently automatable by time $%
t$;}\\
0&\text{otherwise;}\end{cases}" display="block"><mrow><mrow><msub><mi>η</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mtr><mtd class="ltx_align_left" columnalign="left"><mrow><msub><mi>η</mi><mtext>init</mtext></msub><mo lspace="0.222em" rspace="0.222em">⋅</mo><msup><mrow><mo>(</mo><mstyle displaystyle="false"><mfrac><mrow><mi>E</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><msub><mi>E</mi><mi>i</mi></msub></mfrac></mstyle><mo>)</mo></mrow><msub><mi>η</mi><mtext>slope</mtext></msub></msup></mrow></mtd><mtd class="ltx_align_left" columnalign="left"><mrow><mtext>if task&#160;</mtext><mi>i</mi><mtext>&#160;is efficiently automatable by time&#160;</mtext><mi>t</mi><mtext>;</mtext></mrow></mtd></mtr><mtr><mtd class="ltx_align_left" columnalign="left"><mn>0</mn></mtd><mtd class="ltx_align_left" columnalign="left"><mtext>otherwise;</mtext></mtd></mtr></mtable></mrow></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math id="S3.SS2.p3.m4" class="ltx_Math" alttext="\eta_{\text{init}}" display="inline"><msub><mi>η</mi><mtext>init</mtext></msub></math> is a parameter representing the initial efficiency when a task first gets automatable, and <math id="S3.SS2.p3.m5" class="ltx_Math" alttext="\eta_{\text{slope}}" display="inline"><msub><mi>η</mi><mtext>slope</mtext></msub></math> is a parameter controlling how quickly automated coders’ efficiency continues to improve afterward. This can be intuitively understood as:</p>
<table id="S3.Ex26" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span class="ltx_text ltx_markedasmath">each doubling of effective compute <math id="S3.Ex26.m1.m1" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math></span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S3.Ex27" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex27.m1" class="ltx_Math" alttext="\downarrow" display="block"><mo stretchy="false">↓</mo></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<table id="S3.Ex28" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span class="ltx_text ltx_markedasmath"><math id="S3.Ex28.m1.m1" class="ltx_Math" alttext="\eta_{\text{slope}}" display="inline"><msub><mi>η</mi><mtext>slope</mtext></msub></math> doublings of coding automation efficiency.</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">By <a href="#S3.SS1" title="3.1 Coding automation fraction ‣ 3 Coding automation" class="ltx_ref">our definition</a> of when a coding task is efficiently automatable, the initial conversion rate <math id="S3.SS2.p3.m6" class="ltx_Math" alttext="\eta_{\text{init}}" display="inline"><msub><mi>η</mi><mtext>init</mtext></msub></math> is the ratio of the total number of human coders to the amount of automation compute in the present-day.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p class="ltx_p">This model of automation efficiency <math id="S3.SS2.p4.m1" class="ltx_Math" alttext="\eta_{i}(t)" display="inline"><mrow><msub><mi>η</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> makes the simplifying assumption that the relationship between effective compute and efficiency stays consistent across different efficiency levels, which is technically false. However, we think changing this would not substantially affect results.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Aggregate coding labor</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">We next discuss how the increasing AI coding abilities feed back into <span class="ltx_text ltx_font_italic">aggregate coding labor</span>, which in turn influences experiment throughput. Recall that experiment throughput (i.e. the capacity of the project to implement and run experiments) was a function of coding labor and experiment compute, and coding labor <math id="S3.SS3.p1.m1" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> was described as “the number of full-time-human-equivalents”. We want <math id="S3.SS3.p1.m2" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> to account for both human coding labor and AI coding labor, so we now call it “aggregate coding labor”. The number of human coders will be denoted by <math id="S3.SS3.p1.m3" class="ltx_Math" alttext="L_{C,H}(t)" display="inline"><mrow><msub><mi>L</mi><mrow><mi>C</mi><mo>,</mo><mi>H</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> instead.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p class="ltx_p">Recall that we use indices <math id="S3.SS3.p2.m1" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> in the interval <math id="S3.SS3.p2.m2" class="ltx_Math" alttext="[0,1]" display="inline"><mrow><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></math> to represent the different coding tasks involved in implementing AI experiments. We write <math id="S3.SS3.p2.m3" class="ltx_Math" alttext="L_{C,H,i}(t)" display="inline"><mrow><msub><mi>L</mi><mrow><mi>C</mi><mo>,</mo><mi>H</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> and <math id="S3.SS3.p2.m4" class="ltx_Math" alttext="C_{\text{aut},i}(t)" display="inline"><mrow><msub><mi>C</mi><mrow><mtext>aut</mtext><mo>,</mo><mi>i</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>, respectively, for the amount of human coding labor and AI coding labor allocated to task <math id="S3.SS3.p2.m5" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>. The aggregate coding labor for task <math id="S3.SS3.p2.m6" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> is</p>
<table id="S3.Ex29" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex29.m1" class="ltx_Math" alttext="G_{i}(t)=L_{C,H,i}(t)+\eta_{i}(t)\cdot C_{\text{aut},i}(t)," display="block"><mrow><mrow><mrow><msub><mi>G</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>L</mi><mrow><mi>C</mi><mo>,</mo><mi>H</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mrow><msub><mi>η</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">⋅</mo><msub><mi>C</mi><mrow><mtext>aut</mtext><mo>,</mo><mi>i</mi></mrow></msub></mrow><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">since <math id="S3.SS3.p2.m7" class="ltx_Math" alttext="\eta_{i}(t)" display="inline"><mrow><msub><mi>η</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is the conversion rate between units of automation compute and human coders for task <math id="S3.SS3.p2.m8" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p class="ltx_p">If AIs cheaply automate some coding tasks but not others, what effects will that have on coding labor? This depends how much one can substitute the automatable tasks for the non-automatable tasks. But if <math id="S3.SS3.p3.m1" class="ltx_Math" alttext="G_{i}(t)" display="inline"><mrow><msub><mi>G</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> goes to infinity for, say, 90% of the tasks, this shouldn’t cause <math id="S3.SS3.p3.m2" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> to go to infinity since coding will then bottleneck on the remaining 10% of tasks. We choose to model this using a task-based CES (“constant elasticity of substitution”) production function with a parameter <math id="S3.SS3.p3.m3" class="ltx_Math" alttext="\rho_{C}<0" display="inline"><mrow><msub><mi>ρ</mi><mi>C</mi></msub><mo>&lt;</mo><mn>0</mn></mrow></math> that controls the level of substitutability. We are unsure about how well task-based CES functions model reality, and there are known issues with them [<span class="ltx_text" style="color:#0000FF;">ELI-TODO: cite</span>], but they are the best tool we know of for this job (we’d be interested in work that more granularly models the coding workflow).</p>
</div>
<details><summary id="explicit-formula-for-lct">Explicit formula for <math id="S3.SS3.p4.m1" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>.</summary><div id="S3.SS3.p4" class="ltx_para">

<table id="S3.Ex30" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex30.m1" class="ltx_Math" alttext="L_{C}(t)=\left(\int_{0}^{1}G_{i}(t)^{\rho_{C}}\,di\right)^{1/\rho_{C}}=\left(%
\int_{0}^{1}(L_{C,H,i}(t)+\eta_{i}(t)\cdot C_{\text{aut},i}(t))^{\rho_{C}}\,di%
\right)^{1/\rho_{C}}." display="block"><mrow><mrow><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><msup><mrow><mo>(</mo><mrow><msubsup><mo lspace="0em">∫</mo><mn>0</mn><mn>1</mn></msubsup><mrow><msub><mi>G</mi><mi>i</mi></msub><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><msub><mi>ρ</mi><mi>C</mi></msub></msup><mo lspace="0em">⁢</mo><mrow><mo rspace="0em">𝑑</mo><mi>i</mi></mrow></mrow></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><msub><mi>ρ</mi><mi>C</mi></msub></mrow></msup><mo>=</mo><msup><mrow><mo>(</mo><mrow><msubsup><mo lspace="0em" rspace="0em">∫</mo><mn>0</mn><mn>1</mn></msubsup><mrow><msup><mrow><mo stretchy="false">(</mo><mrow><mrow><msub><mi>L</mi><mrow><mi>C</mi><mo>,</mo><mi>H</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mrow><msub><mi>η</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo rspace="0.055em" stretchy="false">)</mo></mrow></mrow><mo rspace="0.222em">⋅</mo><msub><mi>C</mi><mrow><mtext>aut</mtext><mo>,</mo><mi>i</mi></mrow></msub></mrow><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><mo stretchy="false">)</mo></mrow><msub><mi>ρ</mi><mi>C</mi></msub></msup><mo lspace="0em">⁢</mo><mrow><mo rspace="0em">𝑑</mo><mi>i</mi></mrow></mrow></mrow><mo>)</mo></mrow><mrow><mn>1</mn><mo>/</mo><msub><mi>ρ</mi><mi>C</mi></msub></mrow></msup></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>

</div></details>
<div id="S3.SS3.p5" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">What is <math id="S3.SS3.p5.m1" class="ltx_Math" alttext="\rho_{C}" display="inline"><msub><mi>ρ</mi><mi>C</mi></msub></math>?</span> The smaller the substitution parameter <math id="S3.SS3.p5.m2" class="ltx_Math" alttext="\rho_{C}<0" display="inline"><mrow><msub><mi>ρ</mi><mi>C</mi></msub><mo>&lt;</mo><mn>0</mn></mrow></math>, the more coding bottlenecks on the tasks with little coding labor. Put differently, <math id="S3.SS3.p5.m3" class="ltx_Math" alttext="\rho_{C}" display="inline"><msub><mi>ρ</mi><mi>C</mi></msub></math> much smaller than 0 would mean coding AI experiments is a fairly rigid set of tasks that must always be done, and <math id="S3.SS3.p5.m4" class="ltx_Math" alttext="\rho_{C}" display="inline"><msub><mi>ρ</mi><mi>C</mi></msub></math> close to 0 would mean that one can more easily substitute easy-to-automate tasks for hard-to-automate tasks.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p class="ltx_p">When running simulations of our model, at each timestep we set the allocations <math id="S3.SS3.p6.m1" class="ltx_Math" alttext="L_{C,H,i}(t)" display="inline"><mrow><msub><mi>L</mi><mrow><mi>C</mi><mo>,</mo><mi>H</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> and <math id="S3.SS3.p6.m2" class="ltx_Math" alttext="C_{\text{aut},i}(t)" display="inline"><mrow><msub><mi>C</mi><mrow><mtext>aut</mtext><mo>,</mo><mi>i</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> to maximize the aggregate coding labor <math id="S3.SS3.p6.m3" class="ltx_Math" alttext="L_{C}(t)" display="inline"><mrow><msub><mi>L</mi><mi>C</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> (subject to the constraints that the allocations <math id="S3.SS3.p6.m4" class="ltx_Math" alttext="L_{C,H,i}" display="inline"><msub><mi>L</mi><mrow><mi>C</mi><mo>,</mo><mi>H</mi><mo>,</mo><mi>i</mi></mrow></msub></math> sum to the total human coding labor <math id="S3.SS3.p6.m5" class="ltx_Math" alttext="L_{C,H}(t)" display="inline"><mrow><msub><mi>L</mi><mrow><mi>C</mi><mo>,</mo><mi>H</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> and the allocations <math id="S3.SS3.p6.m6" class="ltx_Math" alttext="C_{\text{aut},i}(t)" display="inline"><mrow><msub><mi>C</mi><mrow><mtext>aut</mtext><mo>,</mo><mi>i</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> sum to the total automation compute <math id="S3.SS3.p6.m7" class="ltx_Math" alttext="C_{\text{aut}}(t)" display="inline"><mrow><msub><mi>C</mi><mtext>aut</mtext></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>). This corresponds to the AI project allocating its human and AI coding workforce to where it’s most useful; more concretely, the human coders will be reallocated to tasks that still evade automation while the AI coders will be allocated to the tasks they can efficiently automate (especially those tasks they can automate very quickly).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment selection automation</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text" style="color:#BF8040;">BH-TODO: Update this section given changes made re: algorithmic limits (with funny CES taste distribution).</span></p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p">Experiment selection skill (called “research taste” in our prior work) intuitively measures the value one gets per experiment. Doubling experiment selection skill would have the same effect on progress as doubling experiment throughput (that is, as doubling the number of experiments the project can implement per unit time). We take an expansive definition of experiment selection, including: high-level research direction setting, low-level choices, and experiment ideation and interpretation.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p class="ltx_p">In this section we explain our model of how AIs’ experiment selection skill improves with effective compute and how the experiment selection skills of humans and AIs combine to give the aggregate experiment selection skill.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p class="ltx_p">We discussed how Stage 1 of our model between the present-day and the Automated Coder milestone is largely driven by extrapolating the METR time horizon trend (and deciding whether to extrapolate with an exponential, a superexponential, or a subexponential). Stage 2 of the model behavior, once the Automated Coder milestone is reached, is largely driven by how quickly the experiment selection skill of the AIs increases with effective compute, as well as the initial experiment selection skill at the Automated Coder milestone. The complete automation (and speedup) of coding also plays a notable role, but based on our model simulations the rate at which AIs improve at experiment selection is a bigger driver. Intuitively, additional coding labor can only help so much because the ability to run experiments will eventuall bottleneck on experiment compute. On the other hand, it’s always helpful to have more skillful automated selection of experiments.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Human experiment selection skill</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p">Before we get to improvements in automated experiment selection, we should discuss our model of human experiment selection skill. We model the distribution of the experiment selection skills of human researchers with a lognormal distribution <math id="S4.SS1.p1.m1" class="ltx_Math" alttext="T_{H}" display="inline"><msub><mi>T</mi><mi>H</mi></msub></math> of mean 1 (“lognormal” means <math id="S4.SS1.p1.m2" class="ltx_Math" alttext="\log(T_{H})" display="inline"><mrow><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><msub><mi>T</mi><mi>H</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math> is a normal distribution). We choose the standard deviation of the lognormal so that the experiment selection skill of the <math id="S4.SS1.p1.m3" class="ltx_Math" alttext="99.9^{\text{th}}" display="inline"><msup><mn>99.9</mn><mtext>th</mtext></msup></math> percentile human researcher exceeds that of the median researcher by a factor of <math id="S4.SS1.p1.m4" class="ltx_Math" alttext="T_{\text{var}}" display="inline"><msub><mi>T</mi><mtext>var</mtext></msub></math>. We conducted surveys of frontier AI researchers to inform the value of the parameter <math id="S4.SS1.p1.m5" class="ltx_Math" alttext="T_{\text{var}}" display="inline"><msub><mi>T</mi><mtext>var</mtext></msub></math>.</p>
</div>
<details><summary id="why-use-a-lognormal-distribution-for-experiment-selection-skill">Why use a lognormal distribution for experiment selection skill?</summary><div id="S4.SS1.p2" class="ltx_para">
<p class="ltx_p"> We choose a lognormal distribution because based on surveys of and discussions with frontier AI researchers, it seems likely that the top few percent of researchers provide much more value via experiment selection than typical researchers. Additionally, analogous quantities like scientific citation counts or startup success are often empirically lognormal. </p>
</div></details>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Automated experiment selection skill</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p">As for coding automation fraction and efficiency, the automated experiment selection skill <math id="S4.SS2.p1.m1" class="ltx_Math" alttext="T_{AI}(t)" display="inline"><mrow><msub><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is modeled as a function of effective compute. Whereas we represent the human experiment selection skill by a lognormal distribution <math id="S4.SS2.p1.m2" class="ltx_Math" alttext="T_{H}\sim\text{Lognormal}\left(\mu,\sigma^{2}\right)" display="inline"><mrow><msub><mi>T</mi><mi>H</mi></msub><mo>∼</mo><mrow><mtext>Lognormal</mtext><mo>⁢</mo><mrow><mo>(</mo><mi>μ</mi><mo>,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo>)</mo></mrow></mrow></mrow></math>, <math id="S4.SS2.p1.m3" class="ltx_Math" alttext="T_{AI}(t)" display="inline"><mrow><msub><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is a single number for each time <math id="S4.SS2.p1.m4" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> (we think of the AIs as a single collective entity, unlike for humans).</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p class="ltx_p">We describe the AIs’ experiment selection skill in terms of how many standard deviations <math id="S4.SS2.p2.m1" class="ltx_Math" alttext="\sigma" display="inline"><mi>σ</mi></math> (of the underlying normal of the human distribution) above or below the human median it is, and write <math id="S4.SS2.p2.m2" class="ltx_Math" alttext="T_{AI}^{SD}(t)" display="inline"><mrow><msubsup><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow><mrow><mi>S</mi><mo>⁢</mo><mi>D</mi></mrow></msubsup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> for this quantity. If <math id="S4.SS2.p2.m3" class="ltx_Math" alttext="T_{AI}^{SD}(t)" display="inline"><mrow><msubsup><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow><mrow><mi>S</mi><mo>⁢</mo><mi>D</mi></mrow></msubsup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is negative, this means the AIs’ experiment selection skill is below the human median; and if <math id="S4.SS2.p2.m4" class="ltx_Math" alttext="T_{AI}^{SD}(t)" display="inline"><mrow><msubsup><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow><mrow><mi>S</mi><mo>⁢</mo><mi>D</mi></mrow></msubsup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is positive, this means the AIs’ experiment selection skill is above the human median. We assume the AIs’ experiment selection skill increases by <math id="S4.SS2.p2.m5" class="ltx_Math" alttext="T_{\text{rate}}" display="inline"><msub><mi>T</mi><mtext>rate</mtext></msub></math> standard deviations for each additional OOM (order of magnitude) of effective compute:</p>
<table id="S4.Ex31" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex31.m1" class="ltx_Math" alttext="T_{AI}^{SD}(t)=T_{\text{AC}}+T_{\text{rate}}\left(\overline{E}(t)-\overline{E}%
_{\text{AC}}\right)\quad\text{in human standard deviations $\sigma$}." display="block"><mrow><mrow><mrow><msubsup><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow><mrow><mi>S</mi><mo>⁢</mo><mi>D</mi></mrow></msubsup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>T</mi><mtext>AC</mtext></msub><mo>+</mo><mrow><msub><mi>T</mi><mtext>rate</mtext></msub><mo>⁢</mo><mrow><mo>(</mo><mrow><mrow><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>−</mo><msub><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mtext>AC</mtext></msub></mrow><mo>)</mo></mrow></mrow></mrow><mspace width="1em"></mspace><mrow><mtext>in human standard deviations&#160;</mtext><mi>σ</mi></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">Here <math id="S4.SS2.p2.m6" class="ltx_Math" alttext="T_{\text{AC}}" display="inline"><msub><mi>T</mi><mtext>AC</mtext></msub></math> is a model parameter for the experiment selection skill of the Automated Coder, and <math id="S4.SS2.p2.m7" class="ltx_Math" alttext="\overline{E}_{\text{AC}}=\log(E_{\text{AC}})" display="inline"><mrow><msub><mover accent="true"><mi>E</mi><mo>¯</mo></mover><mtext>AC</mtext></msub><mo>=</mo><mrow><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><msub><mi>E</mi><mtext>AC</mtext></msub><mo stretchy="false">)</mo></mrow></mrow></mrow></math> is the effective compute corresponding to the Automated Coder.</p>
</div>
<figure id="S4.F1" class="ltx_figure"><img src="latex/T_AI.png" id="S4.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="320" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><math id="S4.F1.m2" class="ltx_Math" alttext="T_{AI}^{SD}=2.5" display="inline"><mrow><msubsup><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow><mrow><mi>S</mi><mo>⁢</mo><mi>D</mi></mrow></msubsup><mo>=</mo><mn>2.5</mn></mrow></math> means the AIs’ skill is 2.5 standard deviations above the human median <span class="ltx_text" style="color:#FF0000;">(Need to make a new figure)</span></figcaption>
</figure>
<details><summary id="explicit-formula-for-tait">Explicit formula for <math id="S4.SS2.p3.m1" class="ltx_Math" alttext="T_{AI}(t)" display="inline"><mrow><msub><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math></summary><div id="S4.SS2.p3" class="ltx_para">
<p class="ltx_p">
Moving from standard deviations to absolute units, the AIs’ experiment selection skill is</p>
<table id="S4.Ex32" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex32.m1" class="ltx_Math" alttext="T_{AI}(t)=\exp\left(\mu+\sigma\,T_{AI}^{SD}(t)\right)," display="block"><mrow><mrow><mrow><msub><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>exp</mi><mo>⁡</mo><mrow><mo>(</mo><mrow><mi>μ</mi><mo>+</mo><mrow><mi>σ</mi><mo lspace="0.170em">⁢</mo><msubsup><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow><mrow><mi>S</mi><mo>⁢</mo><mi>D</mi></mrow></msubsup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">where <math id="S4.SS2.p3.m2" class="ltx_Math" alttext="\mu" display="inline"><mi>μ</mi></math> and <math id="S4.SS2.p3.m3" class="ltx_Math" alttext="\sigma" display="inline"><mi>σ</mi></math> were the parameters for the human experiment selection skill distribution <math id="S4.SS2.p3.m4" class="ltx_Math" alttext="T_{H}\sim\text{Lognormal}\left(\mu,\sigma^{2}\right)" display="inline"><mrow><msub><mi>T</mi><mi>H</mi></msub><mo>∼</mo><mrow><mtext>Lognormal</mtext><mo>⁢</mo><mrow><mo>(</mo><mi>μ</mi><mo>,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo>)</mo></mrow></mrow></mrow></math>.
</p>
</div></details>
<figure id="S4.SS2.fig1" class="ltx_figure"><img src="latex/Stage2.png" id="S4.SS2.g1" class="ltx_graphics ltx_img_landscape" width="479" height="352" alt="[Uncaptioned image]">
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Aggregate experiment selection skill</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p">The aggregate experiment selection skill <math id="S4.SS3.p1.m1" class="ltx_Math" alttext="T(t)" display="inline"><mrow><mi>T</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> measures the average value per experiment, when one accounts for both human and AI experiment selection skill. When the AIs’ experiment selection skill is better than that of the best human researcher, then <math id="S4.SS3.p1.m2" class="ltx_Math" alttext="T(t)" display="inline"><mrow><mi>T</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math> is just <math id="S4.SS3.p1.m3" class="ltx_Math" alttext="T_{AI}(t)" display="inline"><mrow><msub><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow></math>. Before that’s the case, our model assumes that each human researcher with lower skill than the AIs is lifted up to the level of the AIs. That is, the distribution of human experiment selection skill <span class="ltx_text ltx_font_italic">uplifted by the AIs</span> is</p>
<table id="S4.Ex33" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex33.m1" class="ltx_Math" alttext="\max\left(T_{H},T_{AI}(t)\right)." display="block"><mrow><mrow><mi>max</mi><mo>⁡</mo><mrow><mo>(</mo><msub><mi>T</mi><mi>H</mi></msub><mo>,</mo><mrow><msub><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>)</mo></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p">The aggregate experiment selection skill (which is a single number rather than a distribution) is the average of this new distribution:</p>
<table id="S4.Ex34" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex34.m1" class="ltx_Math" alttext="T(t)=\mathbb{E}\left[\max\left(T_{H},T_{AI}(t)\right)\right]." display="block"><mrow><mrow><mrow><mi>T</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>𝔼</mi><mo>⁢</mo><mrow><mo>[</mo><mrow><mi>max</mi><mo>⁡</mo><mrow><mo>(</mo><msub><mi>T</mi><mi>H</mi></msub><mo>,</mo><mrow><msub><mi>T</mi><mrow><mi>A</mi><mo>⁢</mo><mi>I</mi></mrow></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></mrow><mo>)</mo></mrow></mrow><mo>]</mo></mrow></mrow></mrow><mo lspace="0em">.</mo></mrow></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p class="ltx_p">We currently do not model the <span class="ltx_text ltx_font_italic">quantity</span> of labor needed to do experiment selection, and believe this may not drastically change results, since for experiment selection, quality matters much more than quantity.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Zooming out again</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text" style="color:#FF00FF;">ALEX-SUGGESTION: Maybe this would be a good place to talk about Stage 3 and whether or not we get a software intelligence explosion.</span></p>
</div>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p"><span class="ltx_text" style="color:#FF0000;">ALEX-TODO: I think Eli wants a recap section summarizing the whole model and with all the equations?</span></p>
</div>
</section>
</article>
</div>

</div>
<div class="footnotes"><h2>Footnotes</h2><ol><li id="fn1"><p>In our formulas, <math id="footnote1.m1" class="ltx_Math" alttext="\tau" display="inline"><mi>τ</mi></math> actually represents the present-day increase in log(effective compute) needed to double time horizon. While website users enter a doubling time parameter (in units of time), this is then automatically converted to the analogous quantity for log(effective compute) that appear in the formulas. <a href="#fnref1">↩</a></p></li><li id="fn2"><p>Although we initially talked about time horizon growing exponentially <em class="ltx_emph ltx_font_italic">as a function of time</em>, the discussion translates to talking about time horizon as a function of (OOMs of) effective compute. <a href="#fnref2">↩</a></p></li><li id="fn3"><p>In future model iterations, we may switch to using something like the Epoch Capabilities Index as our core capabilities metric. <a href="#fnref3">↩</a></p></li><li id="fn4"><p>Technically, with infinite compute you could code something up to search the space of all possible AI designs, but that takes time and thus does not provide an infinite speedup. <a href="#fnref4">↩</a></p></li><li id="fn5"><p>In the definition of AI software R&amp;D uplift, we only transport <span class="ltx_text ltx_font_italic">the AIs</span> back to the present-day, not the extra experiment/automation compute and the extra human labor that will be available at time <math id="footnote5.m1" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>. <a href="#fnref5">↩</a></p></li></ol></div>