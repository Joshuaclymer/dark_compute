<!-- Explanation Section Component -->
<div class="explanation-section" style="background: #f9f9f9; border-radius: 8px; padding: 25px; margin-bottom: 30px;">
    <h2 style="font-size: 20px; font-weight: 700; margin-bottom: 15px; color: #222;">
        How This Model Works
    </h2>
    <div style="font-size: 14px; line-height: 1.7; color: #555;">
        <p style="margin-bottom: 12px;">
            This model uses the <strong>AI Takeoff Trajectory Predictor</strong> to estimate when key AI capability milestones will be reached:
        </p>
        <ul style="margin-left: 20px; margin-bottom: 12px;">
            <li style="margin-bottom: 8px;"><strong>AC (Automated Coder):</strong> AI can automate software engineering tasks</li>
            <li style="margin-bottom: 8px;"><strong>SAR (Strong AI Researcher):</strong> AI can perform AI research at superhuman level</li>
            <li style="margin-bottom: 8px;"><strong>ASI (Artificial Superintelligence):</strong> AI far beyond human capability</li>
        </ul>
        <p style="margin-bottom: 12px;">
            The <strong>handoff duration</strong> is the time between AC and SAR - the critical period during which AI systems become capable of recursive self-improvement.
        </p>
        <p>
            The P(Catastrophe) curves show how the probability of AI takeover and human power grabs depends on this handoff duration, with shorter durations corresponding to higher risk.
        </p>
    </div>
</div>
